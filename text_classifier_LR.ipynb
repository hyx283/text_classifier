{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classifier_ok.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7UyqcsIByMnW",
        "colab_type": "code",
        "outputId": "7366b68b-de21-4806-9dbb-3168b687f2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install PyDrive # 安装一个包\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyDrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K    100% |████████████████████████████████| 993kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.11.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.4)\n",
            "Building wheels for collected packages: PyDrive\n",
            "  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built PyDrive\n",
            "Installing collected packages: PyDrive\n",
            "Successfully installed PyDrive-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0HDaWXWwyZwj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "# 以下两句代码在 Google Colab 才需要添加，其他平台忽略\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42vLTDz4yPwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SxGtml9L_b59",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # 2. Auto-iterate using the query syntax\n",
        "# #    https://developers.google.com/drive/v2/web/search-parameters\n",
        "# file_list = drive.ListFile(\n",
        "#     {'q': \"'https://drive.google.com/open?id=1AFxy5ICODGYsdtDYfBzJK6AiVlxyjPHx' in parents\"}).GetList()\n",
        "\n",
        "# for f in file_list:\n",
        "#   # 3. Create & download by id.\n",
        "#   print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "#   fname = os.path.join(local_download_path, f['title'])\n",
        "#   print('downloading to {}'.format(fname))\n",
        "#   f_ = drive.CreateFile({'id': f['id']})\n",
        "#   f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R32lR-Ly_qdN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download = drive.CreateFile({'id':'1AFxy5ICODGYsdtDYfBzJK6AiVlxyjPHx'})\n",
        "download.GetContentFile('train.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rfF5feuv_9oK",
        "colab_type": "code",
        "outputId": "7f7f8831-731b-4c1c-92f6-288930f39ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  sample_data  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "igH2zD_zHY0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_i4RHqhvACXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.txt', sep='\\t', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-gFHdwXIZ7x",
        "colab_type": "code",
        "outputId": "55336b9d-42e2-4360-b054-5e63b4dced87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>《青蛇》造型师默认新《红楼梦》额妆抄袭（图） 凡是看过电影《青蛇》的人，都不会忘记青白二蛇的...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>６．１６日剧榜　＜最后的朋友＞　亮最后杀招成功登顶 《最后的朋友》本周的电视剧排行榜单依然只...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>超乎想象的好看《纳尼亚传奇２：凯斯宾王子》 现时资讯如此发达，搜狐电影评审团几乎人人在没有看...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>吴宇森：赤壁大战不会出现在上集 “希望《赤壁》能给你们不一样的感觉。”对于自己刚刚拍完的影片...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>组图：《多情女人痴情男》陈浩民现场耍宝 陈浩民：外面的朋友大家好，现在是搜狐现场直播，欢迎《...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0                                                  1\n",
              "0  娱乐  《青蛇》造型师默认新《红楼梦》额妆抄袭（图） 凡是看过电影《青蛇》的人，都不会忘记青白二蛇的...\n",
              "1  娱乐  ６．１６日剧榜　＜最后的朋友＞　亮最后杀招成功登顶 《最后的朋友》本周的电视剧排行榜单依然只...\n",
              "2  娱乐  超乎想象的好看《纳尼亚传奇２：凯斯宾王子》 现时资讯如此发达，搜狐电影评审团几乎人人在没有看...\n",
              "3  娱乐  吴宇森：赤壁大战不会出现在上集 “希望《赤壁》能给你们不一样的感觉。”对于自己刚刚拍完的影片...\n",
              "4  娱乐  组图：《多情女人痴情男》陈浩民现场耍宝 陈浩民：外面的朋友大家好，现在是搜狐现场直播，欢迎《..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "lN47q87zIw4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download = drive.CreateFile({'id':'1BmP9IbcJK-XdnKnsP7Ta6cNwZsYpewWt'})\n",
        "download.GetContentFile('test.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zi6wlG0KJJKG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('test.txt', sep='\\t', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbTipt03JSLH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df.columns = ['分类', '文章']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jhFklB5kJX-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download = drive.CreateFile({'id':'1rOI0ufmOz9SWBqt6quFY7xikffqyxh-N'})\n",
        "download.GetContentFile('stopwords.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0IiKpm-Jn4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('stopwords.txt', encoding='utf8') as file:\n",
        "    stopWord_list = [k.strip() for k in file.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_f5Lw8bjJrTr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42L70fnRJugk",
        "colab_type": "code",
        "outputId": "eb67de7a-bbee-441b-d6be-49cc12b7d344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "cell_type": "code",
      "source": [
        "stopword_list = [k.strip() for k in open('stopwords.txt', encoding='utf8').readlines() if k.strip() != '']\n",
        "cutWords_list = []\n",
        "i = 0\n",
        "startTime = time.time()\n",
        "for article in train_df['文章']:\n",
        "    cutWords = [k for k in jieba.cut(article) if k not in stopword_list]\n",
        "    i += 1\n",
        "    if i % 1000 == 0:\n",
        "        print('前%d篇文章分词共花费%.2f秒' %(i, time.time()-startTime))\n",
        "    cutWords_list.append(cutWords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.975 seconds.\n",
            "Prefix dict has been built succesfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "前1000篇文章分词共花费47.18秒\n",
            "前2000篇文章分词共花费91.91秒\n",
            "前3000篇文章分词共花费185.69秒\n",
            "前4000篇文章分词共花费275.88秒\n",
            "前5000篇文章分词共花费361.28秒\n",
            "前6000篇文章分词共花费451.05秒\n",
            "前7000篇文章分词共花费475.68秒\n",
            "前8000篇文章分词共花费500.67秒\n",
            "前9000篇文章分词共花费538.80秒\n",
            "前10000篇文章分词共花费575.11秒\n",
            "前11000篇文章分词共花费617.60秒\n",
            "前12000篇文章分词共花费663.64秒\n",
            "前13000篇文章分词共花费691.41秒\n",
            "前14000篇文章分词共花费717.52秒\n",
            "前15000篇文章分词共花费753.14秒\n",
            "前16000篇文章分词共花费789.96秒\n",
            "前17000篇文章分词共花费825.81秒\n",
            "前18000篇文章分词共花费860.11秒\n",
            "前19000篇文章分词共花费941.06秒\n",
            "前20000篇文章分词共花费1022.69秒\n",
            "前21000篇文章分词共花费1042.51秒\n",
            "前22000篇文章分词共花费1062.79秒\n",
            "前23000篇文章分词共花费1094.27秒\n",
            "前24000篇文章分词共花费1125.36秒\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wmHJWGGbRehF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('cutWords_list.txt', 'w') as file: \n",
        "    for cutWords in cutWords_list:\n",
        "        file.write(' '.join(cutWords) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4FrAtkX3RoWE",
        "colab_type": "code",
        "outputId": "040753ef-c498-482c-e8a4-0294815017a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  cutWords_list.txt  sample_data  stopwords.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lYKIjvxBRur1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uk7H9qgzRxJM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('cutWords_list.txt') as file:\n",
        "    cutWords_list = [k.split() for k in file.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BnSWUiGZSAc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJXLPS86SHuM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rgPls2VSMc-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stopword_list = [k.strip() for k in open('stopwords.txt', encoding='utf8').readlines() if k.strip() != '']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z9FAPgiOSPvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tfv = TfidfVectorizer(min_df=2,  max_features=None,  ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1, stop_words = stopword_list)\n",
        "tfv = TfidfVectorizer(cutWords_list, stop_words=stopword_list, min_df=40, max_df=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cpAG00IKSU28",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "temp_inputlist = [\" \".join(x) for x in cutWords_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "934v4lQiSY01",
        "colab_type": "code",
        "outputId": "e4f7cda0-8cf9-43d4-a5a2-ad12428e3ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "tfv.fit(temp_inputlist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['nbsp'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "        input=[['青蛇', '造型师', '默认', '新', '红楼梦', '额妆', '抄袭', '图', '看过', '电影', '青蛇', '不会', '忘记', '青白', '二蛇', '经典', '造型', '飘逸', '身材', '妩媚', '妆容', '独特', '取材于', '京剧', '女角', '头型', '精华', '处', '片子', '称之为', '额妆', '１', '３', '年', '今天', '新版', '红楼梦', '定妆', '照里', '看到', '这种', '熟悉', '妆容', '片子', '昨日', '知情人', '记者', '报料', '叶锦添...销', '车旅费', '上调', '手机', '报销', '费用', '灾区', '员工', '安抚', '慰问', '措施', '紧锣密鼓', '筹划', '之中', '责任编辑', '赵文琳']],\n",
              "        lowercase=True, max_df=0.3, max_features=None, min_df=40,\n",
              "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
              "        stop_words=['aboard', 'about', 'about', 'about', 'above', 'above', 'according', 'according to', 'across', 'across', 'afore', 'after', 'after', 'after', 'afterwards', 'again', 'against', 'against', 'against', 'agin', 'all', 'all', 'almost', 'almost', 'alone', 'along', 'along', 'alongside', 'already',... '）', '，', '：', '：', '；', '；', '？', '？', '？', '＿', '￣', '&nbsp;', '&nbsp', 'pp', 'px', '摄于', 'info'],\n",
              "        strip_accents=None, sublinear_tf=False,\n",
              "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
              "        vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "YUiZ3XqnS2ny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_all = tfv.transform(temp_inputlist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1cMrbRJaSu-l",
        "colab_type": "code",
        "outputId": "ae4ff7e8-c536-453e-e4f8-7debbfcfe1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "print('词表大小:', len(tfv.vocabulary_))\n",
        "print(X_all.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "词表大小: 27752\n",
            "(24000, 27752)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z7239jINTK6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train_df = pd.read_csv('train.txt', sep='\\t', header=None)\n",
        "labelEncoder = LabelEncoder()\n",
        "y = labelEncoder.fit_transform(train_df[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EEv-cZbwTfxR",
        "colab_type": "code",
        "outputId": "99f15a0d-2b7c-459c-9e95-71aff26e2e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X_all, y, test_size=0.2)\n",
        "logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "logistic_model.fit(train_X, train_y)\n",
        "logistic_model.score(test_X, test_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8589583333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "_F9o6qg5XZeg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('tfv.model', 'wb') as file:\n",
        "    save = {\n",
        "        'labelEncoder' : labelEncoder,\n",
        "        'tfidfVectorizer' : tfv,\n",
        "        'logistic_model' : logistic_model\n",
        "    }\n",
        "    pickle.dump(save, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYLfL4q5XvmQ",
        "colab_type": "code",
        "outputId": "9ad5cf65-a471-4b2c-ce78-49db124c68a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".   adc.json  cutWords_list.txt  stopwords.txt\ttfidf.model  train.txt\n",
            "..  .config   sample_data\t test.txt\ttfv.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dJM4pRaZYD0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('tfv.model', 'rb') as file:\n",
        "    tfidf_model = pickle.load(file)\n",
        "    tfidfVectorizer = tfidf_model['tfidfVectorizer']\n",
        "    labelEncoder = tfidf_model['labelEncoder']\n",
        "    logistic_model = tfidf_model['logistic_model']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6e3sX921Y2Qd",
        "colab_type": "code",
        "outputId": "f2c66441-bbc9-4a18-d30e-378f33de42be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.txt', sep='\\t', header=None)\n",
        "X = tfidfVectorizer.transform(train_df[1])\n",
        "y = labelEncoder.transform(train_df[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['nbsp'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sEHd-r3SY85r",
        "colab_type": "code",
        "outputId": "385ceb4a-e1d6-4283-c3dc-9c932b151e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "cv_split = ShuffleSplit(n_splits=5, test_size=0.3)\n",
        "score_ndarray = cross_val_score(logistic_model, X, y, cv=cv_split)\n",
        "print(score_ndarray)\n",
        "print(score_ndarray.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.81972222 0.81666667 0.81527778 0.81972222 0.82194444]\n",
            "0.8186666666666665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VmfYplzkZfXB",
        "colab_type": "code",
        "outputId": "86494e68-54f6-4e3a-ab55-ca094f0f7d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
        "logistic_model = LogisticRegressionCV(multi_class='multinomial', solver='lbfgs')\n",
        "logistic_model.fit(train_X, train_y)\n",
        "predict_y = logistic_model.predict(test_X)\n",
        "pd.DataFrame(confusion_matrix(test_y, predict_y), \n",
        "             columns=labelEncoder.classes_, \n",
        "             index=labelEncoder.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>体育</th>\n",
              "      <th>健康</th>\n",
              "      <th>女人</th>\n",
              "      <th>娱乐</th>\n",
              "      <th>房地产</th>\n",
              "      <th>教育</th>\n",
              "      <th>文化</th>\n",
              "      <th>新闻</th>\n",
              "      <th>旅游</th>\n",
              "      <th>汽车</th>\n",
              "      <th>科技</th>\n",
              "      <th>财经</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>体育</th>\n",
              "      <td>385</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>健康</th>\n",
              "      <td>4</td>\n",
              "      <td>308</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>女人</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>320</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>娱乐</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>371</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>房地产</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>321</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>教育</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>332</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>文化</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>326</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>新闻</th>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>362</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>旅游</th>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>329</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>汽车</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>374</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>科技</th>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>320</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>财经</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      体育   健康   女人   娱乐  房地产   教育   文化   新闻   旅游   汽车   科技   财经\n",
              "体育   385    1   10    5    1    6   12    1    3    2    4    5\n",
              "健康     4  308    9    3    4    9   13    5   14    1    6    6\n",
              "女人     3    7  320   16    3    3   12    2    3    3    1    0\n",
              "娱乐     4    2    6  371    0    2   14    2    4    1    3    2\n",
              "房地产    3    7    7    5  321    5    4    9    7    2    8   19\n",
              "教育     1    7    4    0    2  332   16    3    9    4    3    4\n",
              "文化     3    7   10   16    2    4  326    6    7    3    6    1\n",
              "新闻     3   10    8    2    5    3    8  362   10    1    4   11\n",
              "旅游     2   14    7    5   15    3   21    8  329    1   10    0\n",
              "汽车     1    3    7    0    5    4    3    2    4  374    5    2\n",
              "科技     2   11    8    4   13    6    4    5    8    1  320    8\n",
              "财经     0    8    4    1   11    4    2   14    5    1   11  323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "pH7fiMcFdbh1",
        "colab_type": "code",
        "outputId": "b95f927a-7462-42ed-d07c-06a3979cb47c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def eval_model(y_true, y_pred, labels):\n",
        "    # 计算每个分类的Precision, Recall, f1, support\n",
        "    p, r, f1, s = precision_recall_fscore_support(y_true, y_pred)\n",
        "    # 计算总体的平均Precision, Recall, f1, support\n",
        "    tot_p = np.average(p, weights=s)\n",
        "    tot_r = np.average(r, weights=s)\n",
        "    tot_f1 = np.average(f1, weights=s)\n",
        "    tot_s = np.sum(s)\n",
        "    res1 = pd.DataFrame({\n",
        "        u'Label': labels,\n",
        "        u'Precision': p,\n",
        "        u'Recall': r,\n",
        "        u'F1': f1,\n",
        "        u'Support': s\n",
        "    })\n",
        "    res2 = pd.DataFrame({\n",
        "        u'Label': ['总体'],\n",
        "        u'Precision': [tot_p],\n",
        "        u'Recall': [tot_r],\n",
        "        u'F1': [tot_f1],\n",
        "        u'Support': [tot_s]\n",
        "    })\n",
        "    res2.index = [999]\n",
        "    res = pd.concat([res1, res2])\n",
        "    return res[['Label', 'Precision', 'Recall', 'F1', 'Support']]\n",
        "\n",
        "predict_y = logistic_model.predict(test_X)\n",
        "eval_model(test_y, predict_y, labelEncoder.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>体育</td>\n",
              "      <td>0.934917</td>\n",
              "      <td>0.905000</td>\n",
              "      <td>0.919715</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>健康</td>\n",
              "      <td>0.789687</td>\n",
              "      <td>0.781000</td>\n",
              "      <td>0.785319</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>女人</td>\n",
              "      <td>0.824427</td>\n",
              "      <td>0.864000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>0.876228</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.884044</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>房地产</td>\n",
              "      <td>0.839468</td>\n",
              "      <td>0.821000</td>\n",
              "      <td>0.830131</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>教育</td>\n",
              "      <td>0.862845</td>\n",
              "      <td>0.843000</td>\n",
              "      <td>0.852807</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>文化</td>\n",
              "      <td>0.760967</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.803023</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>新闻</td>\n",
              "      <td>0.827795</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.824887</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>旅游</td>\n",
              "      <td>0.838437</td>\n",
              "      <td>0.794000</td>\n",
              "      <td>0.815614</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>汽车</td>\n",
              "      <td>0.942736</td>\n",
              "      <td>0.889000</td>\n",
              "      <td>0.915080</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>科技</td>\n",
              "      <td>0.786133</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.795455</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>财经</td>\n",
              "      <td>0.831663</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.830831</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>总体</td>\n",
              "      <td>0.842942</td>\n",
              "      <td>0.841333</td>\n",
              "      <td>0.841721</td>\n",
              "      <td>12000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Label  Precision    Recall        F1  Support\n",
              "0      体育   0.934917  0.905000  0.919715     1000\n",
              "1      健康   0.789687  0.781000  0.785319     1000\n",
              "2      女人   0.824427  0.864000  0.843750     1000\n",
              "3      娱乐   0.876228  0.892000  0.884044     1000\n",
              "4     房地产   0.839468  0.821000  0.830131     1000\n",
              "5      教育   0.862845  0.843000  0.852807     1000\n",
              "6      文化   0.760967  0.850000  0.803023     1000\n",
              "7      新闻   0.827795  0.822000  0.824887     1000\n",
              "8      旅游   0.838437  0.794000  0.815614     1000\n",
              "9      汽车   0.942736  0.889000  0.915080     1000\n",
              "10     科技   0.786133  0.805000  0.795455     1000\n",
              "11     财经   0.831663  0.830000  0.830831     1000\n",
              "999    总体   0.842942  0.841333  0.841721    12000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "WzKUm6FddApV",
        "colab_type": "code",
        "outputId": "76604419-c6c6-4b7c-f439-2e413d8fc102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv('test.txt', sep='\\t', header=None)\n",
        "test_X = tfidfVectorizer.transform(test_df[1])\n",
        "test_y = labelEncoder.transform(test_df[0])\n",
        "predict_y = logistic_model.predict(test_X)\n",
        "eval_model(test_y, predict_y, labelEncoder.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>体育</td>\n",
              "      <td>0.934917</td>\n",
              "      <td>0.905000</td>\n",
              "      <td>0.919715</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>健康</td>\n",
              "      <td>0.789687</td>\n",
              "      <td>0.781000</td>\n",
              "      <td>0.785319</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>女人</td>\n",
              "      <td>0.824427</td>\n",
              "      <td>0.864000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>0.876228</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.884044</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>房地产</td>\n",
              "      <td>0.839468</td>\n",
              "      <td>0.821000</td>\n",
              "      <td>0.830131</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>教育</td>\n",
              "      <td>0.862845</td>\n",
              "      <td>0.843000</td>\n",
              "      <td>0.852807</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>文化</td>\n",
              "      <td>0.760967</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.803023</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>新闻</td>\n",
              "      <td>0.827795</td>\n",
              "      <td>0.822000</td>\n",
              "      <td>0.824887</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>旅游</td>\n",
              "      <td>0.838437</td>\n",
              "      <td>0.794000</td>\n",
              "      <td>0.815614</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>汽车</td>\n",
              "      <td>0.942736</td>\n",
              "      <td>0.889000</td>\n",
              "      <td>0.915080</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>科技</td>\n",
              "      <td>0.786133</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.795455</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>财经</td>\n",
              "      <td>0.831663</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.830831</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>总体</td>\n",
              "      <td>0.842942</td>\n",
              "      <td>0.841333</td>\n",
              "      <td>0.841721</td>\n",
              "      <td>12000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Label  Precision    Recall        F1  Support\n",
              "0      体育   0.934917  0.905000  0.919715     1000\n",
              "1      健康   0.789687  0.781000  0.785319     1000\n",
              "2      女人   0.824427  0.864000  0.843750     1000\n",
              "3      娱乐   0.876228  0.892000  0.884044     1000\n",
              "4     房地产   0.839468  0.821000  0.830131     1000\n",
              "5      教育   0.862845  0.843000  0.852807     1000\n",
              "6      文化   0.760967  0.850000  0.803023     1000\n",
              "7      新闻   0.827795  0.822000  0.824887     1000\n",
              "8      旅游   0.838437  0.794000  0.815614     1000\n",
              "9      汽车   0.942736  0.889000  0.915080     1000\n",
              "10     科技   0.786133  0.805000  0.795455     1000\n",
              "11     财经   0.831663  0.830000  0.830831     1000\n",
              "999    总体   0.842942  0.841333  0.841721    12000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}