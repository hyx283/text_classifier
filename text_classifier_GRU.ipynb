{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classifier_GRU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7UyqcsIByMnW",
        "colab_type": "code",
        "outputId": "72de81a4-1dac-46f5-8b98-1d2e975a9f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install PyDrive # 安装一个包\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.4)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.11.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0HDaWXWwyZwj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "# 以下两句代码在 Google Colab 才需要添加，其他平台忽略\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42vLTDz4yPwa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SxGtml9L_b59",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # 2. Auto-iterate using the query syntax\n",
        "# #    https://developers.google.com/drive/v2/web/search-parameters\n",
        "# file_list = drive.ListFile(\n",
        "#     {'q': \"'https://drive.google.com/open?id=1AFxy5ICODGYsdtDYfBzJK6AiVlxyjPHx' in parents\"}).GetList()\n",
        "\n",
        "# for f in file_list:\n",
        "#   # 3. Create & download by id.\n",
        "#   print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "#   fname = os.path.join(local_download_path, f['title'])\n",
        "#   print('downloading to {}'.format(fname))\n",
        "#   f_ = drive.CreateFile({'id': f['id']})\n",
        "#   f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R32lR-Ly_qdN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download = drive.CreateFile({'id':'1AFxy5ICODGYsdtDYfBzJK6AiVlxyjPHx'})\n",
        "download.GetContentFile('train.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rfF5feuv_9oK",
        "colab_type": "code",
        "outputId": "d4469999-d0f3-4db6-8880-7c41b413a79a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  sample_data  stopwords.txt  test.txt\ttrain.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "igH2zD_zHY0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_i4RHqhvACXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train.txt', sep='\\t', header=None,encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-gFHdwXIZ7x",
        "colab_type": "code",
        "outputId": "f098b384-fd2a-4a2c-f84d-570c82d7b415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>《青蛇》造型师默认新《红楼梦》额妆抄袭（图） 凡是看过电影《青蛇》的人，都不会忘记青白二蛇的...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>６．１６日剧榜　＜最后的朋友＞　亮最后杀招成功登顶 《最后的朋友》本周的电视剧排行榜单依然只...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>超乎想象的好看《纳尼亚传奇２：凯斯宾王子》 现时资讯如此发达，搜狐电影评审团几乎人人在没有看...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>吴宇森：赤壁大战不会出现在上集 “希望《赤壁》能给你们不一样的感觉。”对于自己刚刚拍完的影片...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>组图：《多情女人痴情男》陈浩民现场耍宝 陈浩民：外面的朋友大家好，现在是搜狐现场直播，欢迎《...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0                                                  1\n",
              "0  娱乐  《青蛇》造型师默认新《红楼梦》额妆抄袭（图） 凡是看过电影《青蛇》的人，都不会忘记青白二蛇的...\n",
              "1  娱乐  ６．１６日剧榜　＜最后的朋友＞　亮最后杀招成功登顶 《最后的朋友》本周的电视剧排行榜单依然只...\n",
              "2  娱乐  超乎想象的好看《纳尼亚传奇２：凯斯宾王子》 现时资讯如此发达，搜狐电影评审团几乎人人在没有看...\n",
              "3  娱乐  吴宇森：赤壁大战不会出现在上集 “希望《赤壁》能给你们不一样的感觉。”对于自己刚刚拍完的影片...\n",
              "4  娱乐  组图：《多情女人痴情男》陈浩民现场耍宝 陈浩民：外面的朋友大家好，现在是搜狐现场直播，欢迎《..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "bbTipt03JSLH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df.columns = ['分类', '文章']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19alq0ceYRBd",
        "colab_type": "code",
        "outputId": "aeff5094-891d-4450-bd30-751698af5049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "set(train_df['分类'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'体育', '健康', '女人', '娱乐', '房地产', '教育', '文化', '新闻', '旅游', '汽车', '科技', '财经'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "jEXFlJJkYEYN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ty = train_df[train_df.分类=='体育'].文章.values.tolist()\n",
        "jk = train_df[train_df.分类=='健康'].文章.values.tolist()\n",
        "nr = train_df[train_df.分类=='女人'].文章.values.tolist()\n",
        "yl = train_df[train_df.分类=='娱乐'].文章.values.tolist()\n",
        "fdc = train_df[train_df.分类=='房地产'].文章.values.tolist()\n",
        "jy = train_df[train_df.分类=='教育'].文章.values.tolist()\n",
        "wh = train_df[train_df.分类=='文化'].文章.values.tolist()\n",
        "xw = train_df[train_df.分类=='新闻'].文章.values.tolist()\n",
        "ly = train_df[train_df.分类=='旅游'].文章.values.tolist()\n",
        "qc = train_df[train_df.分类=='汽车'].文章.values.tolist()\n",
        "kj = train_df[train_df.分类=='科技'].文章.values.tolist()\n",
        "cj = train_df[train_df.分类=='财经'].文章.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OA8zgwViRF8d",
        "colab_type": "code",
        "outputId": "d454fe03-744c-4918-f6df-e12cf219d35a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "ty[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'欧洲杯观察：足坛格局地震\\u3000东南欧已能占半边天 搜狐体育讯\\u3000土耳其与克罗地亚在本届欧洲杯１／４决赛中相遇，已经注定将有一支非欧洲传统足球发达地区的球队跻身半决赛。这看起来并不起眼，但却是欧洲杯有史以来第一次，连续两届有传统的足球落后地区球队打入欧洲杯的半决赛。不夸张的说，欧洲足球格局，正在地震着。毫无疑问，西欧是欧洲足球水平最发达的地区。德国、意大利、法国、英格兰、荷兰、西班牙等诸多欧洲传统豪强都集中在这个区域。虽然在地理位置上，意大利、法国和西班牙等国应属南欧，但从政治文化上，这些国家都是不折不扣的西欧国家。历届欧洲大赛，西欧国家都是最强有力的竞争者，而且几乎绝大多数时间，冠军都是西欧国家的囊中之物。不过在现代足球早期，东欧足球同样拥有不可小觑的实力。前苏联、前捷克斯洛伐克、前南斯拉夫和匈牙利等国都能与西欧劲旅一较长短。特别是在欧洲杯初办时，东欧足球一度还占据优势。第一届欧洲杯，前苏联、前南斯拉夫和前捷克斯洛伐克三支东欧球队包揽前三名；第二届欧洲杯，冠军虽然被西班牙捧走，但前苏联和匈牙利分获二、三名；第三届欧洲杯，又是两支东欧球队（前南斯拉夫和前捷克斯洛伐克）拱卫一支西欧球队（意大利）。此后一直到第七届欧洲杯之前，总有至少一支东欧球队可以杀进半决赛，前捷克斯洛伐克还曾经勇夺德劳内杯。但是随着世界经济格局的变化，东、西欧政治经济环境差距的迅速拉大，东欧各国足球水平严重下滑，已经开始渐渐难以与西欧国家抗衡。从１９８４年欧洲杯开始，东欧球队再也没有一次能连续两届杀进半决赛。从１９８０年到２０００年的２０年间，连续６届欧洲杯都被西欧（包括地理位置上的北欧）球队获得。欧洲杯已经成为西欧劲旅们私人的玩具。应该说，在那段时间里，东欧足球一直在走下坡路，前苏联和捷克等东欧传统强队偶露峥嵘，只不过凭借的是这些国家甚厚的足球底蕴，但整体上的确远比西欧足球强国逊色很多。不过世事无常，进入２１世纪以来，随着欧洲政治格局的再一次变化，东西欧界线的模糊，以东欧为代表的落后地区的足球事业开始又一次飞速发展。其中像捷克、前南斯拉夫等地区有天赋的球员大举进驻欧洲五大联赛，首先靠借鸡生蛋的模式让各自国家队水平有了大幅度提高；而希腊、土耳其等原本足球水平落后的南欧国家则大力从西欧的足球强国引进教练，从基础上发展了自己的足球运动。上届欧洲杯，希腊低调出征竟然一举夺取欧洲杯冠军，书写了欧洲杯历史上最不可思议的一段神话。当然，从整体实力上来说，希腊并不具备欧洲冠军的水平，本届欧洲杯希腊在小组赛连战皆败就是证明，他们能在欧洲杯上创造奇迹，在于明确的定位以及各路豪强对希腊重视不够。但即便如此，也要希腊具备一定的实力基础，才能从西欧列强身上讨得便宜。不仅如此，在该届欧洲杯上，捷克队打出了一波让人无法忽视的东欧旋风，事实上他们才是非西欧球队的代表，而那支捷克队，拥有与任何一支西欧劲旅相抗的实力。在国际足联国家队排行榜上，那支捷克队也长时间高居第二。如果说一届欧洲杯只是偶然，那么本届欧洲杯就真正吹响了非西欧地区足球崛起的号角。克罗地亚击败不可一世的德国，提前一轮锁定小组第一；而他们在１／４决赛中的对手是土耳其，一支来自亚欧交界处的国家。不论克罗地亚和土耳其谁获胜，都将确保半决赛中有一个非西欧国家席位。这是欧洲足球欠发达地区连续第二届杀进欧洲杯半决赛，在欧洲杯历史上还是第一次（欧洲杯早期，东欧也是足球发达地区）。而这还不算完。在尚未结束争夺的小组中，东欧球队仍然具有竞争力。罗马尼亚在Ｃ组排名第二，并且在最后一轮面对不会全力以赴的荷兰，极有可能杀进８强；Ｄ组俄罗斯与瑞典机会均等，最后一轮获胜的球队就能晋级复赛。也就是说，本届欧洲杯很有可能出现传统意义上的足球落后地区国家在８强中占据半边天的情况，如此大面积的爆发，决不能拿运气来解释。因此我们几乎可以断言，欧洲足球板块，正在发生剧烈的迁徙和碰撞，本届欧洲杯只是一个开始。现任欧足联主席普拉蒂尼的纲领就是大力提携足球欠发达地区，在他的领导下东欧和南欧等地区的足球水平必然还会有持续的发展。也许在俱乐部层面，西欧仍然会是欧洲乃至世界足球的中心，但在国家队层面，以东欧为代表的足球欠发达地区国家却正逐渐撼动着西欧国家的强势。也许未来几年内，东欧国家就能再一次与西欧国家分庭抗礼。这也是绝大多数球迷所乐见的，正如普拉蒂尼所言：“把足球还给踢球的人。”（搜狐体育\\u3000寒锋）（责任编辑：Ｇｅｍｉｎｉ\\u3000）'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "jhFklB5kJX-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download = drive.CreateFile({'id':'1rOI0ufmOz9SWBqt6quFY7xikffqyxh-N'})\n",
        "download.GetContentFile('stopwords.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0IiKpm-Jn4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('stopwords.txt', encoding='utf8') as file:\n",
        "    stopWord_list = [k.strip() for k in file.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iiRw9HzJa1pz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "stopwords=np.array(stopWord_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WfD6BSPAcAhI",
        "colab_type": "code",
        "outputId": "94d8fe63-81e8-4087-f80d-01c7495acb6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# 构建数据集\n",
        "import jieba\n",
        "def preprocess_text(content_lines, sentences, category):\n",
        "    for line in content_lines:\n",
        "        try:\n",
        "            segs=jieba.lcut(line)\n",
        "            segs = filter(lambda x:len(x)>1, segs)\n",
        "            segs = filter(lambda x:x not in stopwords, segs)\n",
        "            sentences.append((\" \".join(segs), category))\n",
        "        except Exception as e:\n",
        "#             print(line)\n",
        "            log.append((\" \".join(line), category))\n",
        "            continue\n",
        "\n",
        "#生成训练数据\n",
        "sentences = []\n",
        "log=[]\n",
        "preprocess_text(ty, sentences, 'ty')\n",
        "preprocess_text(jk, sentences, 'jk')\n",
        "preprocess_text(nr, sentences, 'nr')\n",
        "preprocess_text(yl, sentences, 'yl')\n",
        "preprocess_text(fdc, sentences, 'fdc')\n",
        "preprocess_text(jy, sentences, 'jy')\n",
        "preprocess_text(wh, sentences, 'wh')\n",
        "preprocess_text(xw, sentences, 'xw')\n",
        "preprocess_text(ly, sentences, 'ly')\n",
        "preprocess_text(qc, sentences, 'qc')\n",
        "preprocess_text(kj, sentences, 'kj')\n",
        "preprocess_text(cj, sentences, 'cj')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.651 seconds.\n",
            "Prefix dict has been built succesfully.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "W11g76BZnfew",
        "colab_type": "code",
        "outputId": "12c6be74-09f7-49f1-c728-9c33a32c9322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(sentences),len(log)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "gOhU15Psdc8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download = drive.CreateFile({'id':'1BmP9IbcJK-XdnKnsP7Ta6cNwZsYpewWt'})\n",
        "download.GetContentFile('test.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ujZhsyneEPn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('test.txt', sep='\\t', header=None,encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pw6eS8yPeIDo",
        "colab_type": "code",
        "outputId": "3f3d4906-dffd-4cd5-9f1f-48d9e1714bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>组图：黄健翔拍时装大片　承认口无遮拦 ２００６年之前，他只是最好的体育节目主持人之一。２００...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>奥运明星写真集锦曝光　展现健康时尚（图） 来源：人民网奥运明星奥运明星大满贯――属于最强者的...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>内地票房榜：《功夫熊猫》获全胜　带动内地影市 《功夫熊猫》首映周末逼４０００万２００６年１月...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>编者按： 昨天，央视紧急停播动画片《虹猫蓝兔七侠传》事件经报道后，引发了数十万网民的热烈大辩...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>第十一届上海国际电影节　金爵奖评委名单 ［点击图片进入下一页］金爵奖评委陈冲陈冲（美籍华裔女...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0                                                  1\n",
              "0  娱乐  组图：黄健翔拍时装大片　承认口无遮拦 ２００６年之前，他只是最好的体育节目主持人之一。２００...\n",
              "1  娱乐  奥运明星写真集锦曝光　展现健康时尚（图） 来源：人民网奥运明星奥运明星大满贯――属于最强者的...\n",
              "2  娱乐  内地票房榜：《功夫熊猫》获全胜　带动内地影市 《功夫熊猫》首映周末逼４０００万２００６年１月...\n",
              "3  娱乐  编者按： 昨天，央视紧急停播动画片《虹猫蓝兔七侠传》事件经报道后，引发了数十万网民的热烈大辩...\n",
              "4  娱乐  第十一届上海国际电影节　金爵奖评委名单 ［点击图片进入下一页］金爵奖评委陈冲陈冲（美籍华裔女..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "OW_E5wHmeMTX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_df.columns = ['分类', '文章']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weAGg202eTVY",
        "colab_type": "code",
        "outputId": "554e2f12-edac-4a0c-b184-5482795252aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "set(test_df.分类)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'体育', '健康', '女人', '娱乐', '房地产', '教育', '文化', '新闻', '旅游', '汽车', '科技', '财经'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "ExqFIIaneWzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ty_test = test_df[test_df.分类=='体育'].文章.values.tolist()\n",
        "jk_test = test_df[test_df.分类=='健康'].文章.values.tolist()\n",
        "nr_test = test_df[test_df.分类=='女人'].文章.values.tolist()\n",
        "yl_test = test_df[test_df.分类=='娱乐'].文章.values.tolist()\n",
        "fdc_test = test_df[test_df.分类=='房地产'].文章.values.tolist()\n",
        "jy_test = test_df[test_df.分类=='教育'].文章.values.tolist()\n",
        "wh_test = test_df[test_df.分类=='文化'].文章.values.tolist()\n",
        "xw_test = test_df[test_df.分类=='新闻'].文章.values.tolist()\n",
        "ly_test = test_df[test_df.分类=='旅游'].文章.values.tolist()\n",
        "qc_test = test_df[test_df.分类=='汽车'].文章.values.tolist()\n",
        "kj_test = test_df[test_df.分类=='科技'].文章.values.tolist()\n",
        "cj_test = test_df[test_df.分类=='财经'].文章.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zoF0P-5bieQr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#生成测试数据\n",
        "sentences_test = []\n",
        "\n",
        "preprocess_text(ty_test, sentences_test, 'ty')\n",
        "preprocess_text(jk_test, sentences_test, 'jk')\n",
        "preprocess_text(nr_test, sentences_test, 'nr')\n",
        "preprocess_text(yl_test, sentences_test, 'yl')\n",
        "preprocess_text(fdc_test, sentences_test, 'fdc')\n",
        "preprocess_text(jy_test, sentences_test, 'jy')\n",
        "preprocess_text(wh_test, sentences_test, 'wh')\n",
        "preprocess_text(xw_test, sentences_test, 'xw')\n",
        "preprocess_text(ly_test, sentences_test, 'ly')\n",
        "preprocess_text(qc_test, sentences_test, 'qc')\n",
        "preprocess_text(kj_test, sentences_test, 'kj')\n",
        "preprocess_text(cj_test, sentences_test, 'cj')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WgLObKIUD8D",
        "colab_type": "code",
        "outputId": "d5486a22-3f57-4837-b67f-c45cd625d65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(sentences_test),len(log)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "Jfry3Vwui8Na",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data, train_target= zip(*sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mLZwzFGajYtJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data, test_target= zip(*sentences_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLCoj7z71B-O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "使用RNN完成文本分类\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers.python.layers import encoders\n",
        "\n",
        "learn = tf.contrib.learn\n",
        "\n",
        "FLAGS = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TTlyUBzd1v0i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "cate_dic = {'ty':1, 'jk':2, 'nr':3, 'yl':4, 'fdc':5,'jy':6,'wh':7,'xw':8,'ly':9,'qc':10,'kj':11,'cj':12}\n",
        "train_target = map(lambda x:cate_dic[x], train_target)\n",
        "test_target = map(lambda x:cate_dic[x], test_target)\n",
        "y_train = pandas.Series(train_target)\n",
        "y_test = pandas.Series(test_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lB68zlnF1Ok2",
        "colab_type": "code",
        "outputId": "62cfbc31-e6b9-4830-cfbd-b97ba9c0e1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2215
        }
      },
      "cell_type": "code",
      "source": [
        "# 词袋模型\n",
        "\n",
        "MAX_DOCUMENT_LENGTH = 15\n",
        "MIN_WORD_FREQUENCE = 1\n",
        "EMBEDDING_SIZE = 50\n",
        "global n_words\n",
        "# 处理词汇\n",
        "vocab_processor = learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH, min_frequency=MIN_WORD_FREQUENCE)\n",
        "x_train = np.array(list(vocab_processor.fit_transform(train_data)))\n",
        "x_test = np.array(list(vocab_processor.transform(test_data)))\n",
        "n_words = len(vocab_processor.vocabulary_)\n",
        "print('Total words: %d' % n_words)\n",
        "\n",
        "# GRU分类器\n",
        "def rnn_model(features, target):\n",
        "    \"\"\"用RNN模型(这里用的是GRU)完成文本分类\"\"\"\n",
        "    # Convert indexes of words into embeddings.\n",
        "    # This creates embeddings matrix of [n_words, EMBEDDING_SIZE] and then\n",
        "    # maps word indexes of the sequence into [batch_size, sequence_length,\n",
        "    # EMBEDDING_SIZE].\n",
        "    word_vectors = tf.contrib.layers.embed_sequence(\n",
        "            features, vocab_size=n_words, embed_dim=EMBEDDING_SIZE, scope='words')\n",
        "\n",
        "    # Split into list of embedding per word, while removing doc length dim.\n",
        "    # word_list results to be a list of tensors [batch_size, EMBEDDING_SIZE].\n",
        "    word_list = tf.unstack(word_vectors, axis=1)\n",
        "\n",
        "    # Create a Gated Recurrent Unit cell with hidden size of EMBEDDING_SIZE.\n",
        "    cell = tf.contrib.rnn.GRUCell(EMBEDDING_SIZE)\n",
        "\n",
        "    # Create an unrolled Recurrent Neural Networks to length of\n",
        "    # MAX_DOCUMENT_LENGTH and passes word_list as inputs for each unit.\n",
        "    _, encoding = tf.contrib.rnn.static_rnn(cell, word_list, dtype=tf.float32)\n",
        "\n",
        "    # Given encoding of RNN, take encoding of last step (e.g hidden size of the\n",
        "    # neural network of last step) and pass it as features for logistic\n",
        "    # regression over output classes.\n",
        "    target = tf.one_hot(target, 15, 1, 0)\n",
        "    logits = tf.contrib.layers.fully_connected(encoding, 15, activation_fn=None)\n",
        "    loss = tf.contrib.losses.softmax_cross_entropy(logits, target)\n",
        "\n",
        "    # Create a training op.\n",
        "    train_op = tf.contrib.layers.optimize_loss(\n",
        "            loss,\n",
        "            tf.contrib.framework.get_global_step(),\n",
        "            optimizer='Adam',\n",
        "            learning_rate=0.01)\n",
        "\n",
        "    return ({\n",
        "            'class': tf.argmax(logits, 1),\n",
        "            'prob': tf.nn.softmax(logits)\n",
        "    }, loss, train_op)\n",
        "\n",
        "# Train and predict\n",
        "model_fn = rnn_model\n",
        "classifier = learn.SKCompat(learn.Estimator(model_fn=model_fn))\n",
        "\n",
        "# Train and predict\n",
        "classifier.fit(x_train, y_train, steps=1000)\n",
        "y_predicted = classifier.predict(x_test)['class']\n",
        "score = metrics.accuracy_score(y_test, y_predicted)\n",
        "print('Accuracy: {0:f}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-1dff2f763271>:7: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "Total words: 211406\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1179: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmebsgokt\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f834df73cf8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpmebsgokt'}\n",
            "WARNING:tensorflow:From <ipython-input-31-1dff2f763271>:55: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please feed input to tf.data to support dask.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please feed input to tf.data to support dask.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-31-1dff2f763271>:28: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-31-1dff2f763271>:32: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From <ipython-input-31-1dff2f763271>:39: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:370: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:371: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.compute_weighted_loss instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:103: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:151: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:120: add_arg_scope.<locals>.func_with_args (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
            "Instructions for updating:\n",
            "Use tf.losses.add_loss instead.\n",
            "WARNING:tensorflow:From <ipython-input-31-1dff2f763271>:44: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_global_step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1240: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpmebsgokt/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.7081034, step = 0\n",
            "INFO:tensorflow:global_step/sec: 61.6692\n",
            "INFO:tensorflow:loss = 0.6884328, step = 100 (1.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.588\n",
            "INFO:tensorflow:loss = 0.21968663, step = 200 (1.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.9737\n",
            "INFO:tensorflow:loss = 0.21258864, step = 300 (1.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.9243\n",
            "INFO:tensorflow:loss = 0.024039209, step = 400 (1.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.7239\n",
            "INFO:tensorflow:loss = 0.036281943, step = 500 (1.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 86.0986\n",
            "INFO:tensorflow:loss = 0.045579225, step = 600 (1.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 86.0423\n",
            "INFO:tensorflow:loss = 0.036796484, step = 700 (1.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 84.6316\n",
            "INFO:tensorflow:loss = 0.0480206, step = 800 (1.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 85.3144\n",
            "INFO:tensorflow:loss = 0.027205635, step = 900 (1.170 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpmebsgokt/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.003521381.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpmebsgokt/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Accuracy: 0.838083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I65gvV7PcpsY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def eval_model(y_true, y_pred, labels):\n",
        "    # 计算每个分类的Precision, Recall, f1, support\n",
        "    p, r, f1, s = precision_recall_fscore_support(y_true, y_pred)\n",
        "    # 计算总体的平均Precision, Recall, f1, support\n",
        "    tot_p = np.average(p, weights=s)\n",
        "    tot_r = np.average(r, weights=s)\n",
        "    tot_f1 = np.average(f1, weights=s)\n",
        "    tot_s = np.sum(s)\n",
        "    res1 = pd.DataFrame({\n",
        "        u'Label': labels,\n",
        "        u'Precision': p,\n",
        "        u'Recall': r,\n",
        "        u'F1': f1,\n",
        "        u'Support': s\n",
        "    })\n",
        "    res2 = pd.DataFrame({\n",
        "        u'Label': ['总体'],\n",
        "        u'Precision': [tot_p],\n",
        "        u'Recall': [tot_r],\n",
        "        u'F1': [tot_f1],\n",
        "        u'Support': [tot_s]\n",
        "    })\n",
        "    res2.index = [999]\n",
        "    res = pd.concat([res1, res2])\n",
        "    return res[['Label', 'Precision', 'Recall', 'F1', 'Support']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bs61QrUweH87",
        "colab_type": "code",
        "outputId": "aa58217a-1aca-4200-9b81-f81445442094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "cell_type": "code",
      "source": [
        "eval_model(y_test,y_predicted,list(set(train_df['分类'])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>科技</td>\n",
              "      <td>0.953187</td>\n",
              "      <td>0.957000</td>\n",
              "      <td>0.955090</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>体育</td>\n",
              "      <td>0.847507</td>\n",
              "      <td>0.867000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>旅游</td>\n",
              "      <td>0.893491</td>\n",
              "      <td>0.906000</td>\n",
              "      <td>0.899702</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>文化</td>\n",
              "      <td>0.838894</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.858956</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>汽车</td>\n",
              "      <td>0.893730</td>\n",
              "      <td>0.841000</td>\n",
              "      <td>0.866564</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>房地产</td>\n",
              "      <td>0.860701</td>\n",
              "      <td>0.933000</td>\n",
              "      <td>0.895393</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>新闻</td>\n",
              "      <td>0.775079</td>\n",
              "      <td>0.734000</td>\n",
              "      <td>0.753980</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>财经</td>\n",
              "      <td>0.714724</td>\n",
              "      <td>0.699000</td>\n",
              "      <td>0.706775</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>女人</td>\n",
              "      <td>0.842424</td>\n",
              "      <td>0.834000</td>\n",
              "      <td>0.838191</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>娱乐</td>\n",
              "      <td>0.889447</td>\n",
              "      <td>0.885000</td>\n",
              "      <td>0.887218</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>教育</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.809452</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>健康</td>\n",
              "      <td>0.726166</td>\n",
              "      <td>0.716000</td>\n",
              "      <td>0.721047</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>总体</td>\n",
              "      <td>0.837442</td>\n",
              "      <td>0.838083</td>\n",
              "      <td>0.837459</td>\n",
              "      <td>12000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Label  Precision    Recall        F1  Support\n",
              "0      科技   0.953187  0.957000  0.955090     1000\n",
              "1      体育   0.847507  0.867000  0.857143     1000\n",
              "2      旅游   0.893491  0.906000  0.899702     1000\n",
              "3      文化   0.838894  0.880000  0.858956     1000\n",
              "4      汽车   0.893730  0.841000  0.866564     1000\n",
              "5     房地产   0.860701  0.933000  0.895393     1000\n",
              "6      新闻   0.775079  0.734000  0.753980     1000\n",
              "7      财经   0.714724  0.699000  0.706775     1000\n",
              "8      女人   0.842424  0.834000  0.838191     1000\n",
              "9      娱乐   0.889447  0.885000  0.887218     1000\n",
              "10     教育   0.813953  0.805000  0.809452     1000\n",
              "11     健康   0.726166  0.716000  0.721047     1000\n",
              "999    总体   0.837442  0.838083  0.837459    12000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}